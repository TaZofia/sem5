\documentclass{article}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[polish]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{float}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}

\setlength{\parindent}{0pt}

\title{Sprawozdanie laboratorium lista 5 \\Obliczenia naukowe}
\author{\normalsize Zofia Tarchalska, indeks: 279699}
\date{}

\begin{document}
\maketitle
\section{Wstęp}
Celem tej listy było zaimplementowanie trzech poniższych algorytmów o złożoności $O(n)$, gdzie $n$ to rozmiar macierzy $n \times n$.
\begin{itemize}
    \item funkcja rozwiązująca układ $Ax=b$ metodą eliminacji Gaussa
    \item funkcja wyznaczająca rozkład $LU$ maciezry $A$ metodą eliminacji Gaussa
    \item funkcja rozwiązująca układ $Ax=b$ jeśli już wcześniej został wyznaczony rozkład $LU$
\end{itemize}
Wszystkie te algorytmy mają działać dla macierzy $A$ o specyficznej postaci, która została dokładnie opisana w poleceniu do zadania. Dodatkowo należało zaprogramować wersję podstawową oraz wersję z wybieraniem elementu głównego.

\section{Metoda eliminacji Gaussa}
Główną ideą metody eliminacji Gaussa jest doprowadzenie macierzy do postaci, w której pod przekątną znajdują się same zera. Uzyskujemy to poprzez mnożenie kolejnych wierszy macierzy przez odpowiednie czynniki i odejmowanie ich od wierszy następujących po nich. Poprawny schemat:


Eliminujemy zmienną $x_k$ z wierszy od $k + 1$ do $n$. Mnożymy $k-te$ równanie przez 
\[
    l_{ik} = \frac{a_{ik}}{a_{kk}} \quad \text{dla } i \in \{k + 1, ..., n\}
\]

Kiedy jednak na przekątnej w miejscu $a_{kk}$ będzie $0$ metoda może powodować błąd numeryczny, ponieważ nastąpi dzielenie przez $0$. W przeciwnym wypadku, po wykonaniu odpowiednich kroków kolejno dla wszystkich wierszy macierzy, otrzymujemy macierz górnotrójkątną. 

\subsection{Wariant pierwszy - bez wyboru elementu głównego}
Ten wariant nie zabezpiecza nas przed opisanym powyżej błędem numerycznym.

\subsubsection{Złożoność czasowa}
W niezoptymalizowanej wersji algorytmu złożoność wynosiłaby $O(n^3)$, ponieważ mamy 3 pętle \texttt{for} przechodzące po elementach macierzy. Dla każdego wiersza w macierzy wyznaczamy czynnik przez który przemnażamy ten wiersz po czym odejmujemy go od kolejnych wierszy (musimy przejść po wszytskich elementach w danym wierszu, a macierz ma wymiary $n \times n$). Jednak wykorzystując blokową strukturę macierzy A da się sprowadzić ten algorytm do złożoności $O(n)$. Wiemy, że rozmiar pojedynczego bloku ma jakiś określony rozmiar. Oznaczmy go przez l. Zatem pod przekątną macierzy jest maksymalnie l elementów, które są niezerowe. Dodatkowo każdy wiersz, o indeksie większym niż 1 ma od lewej same zera, następnie l leżących po sobie niezerowych wartości i znów zera (chyba, że np. $k+l$ daje już indeks ostatniej kolumny, wtedy nie ma zar od końca). Możemy zatem wykonywać ten algorytm tylko dla wierszy i elementów, dla których ma to sens (oszczędzimy sobie przetwarzania ogromnej liczby samych zer). Możemy zatem odejmować tylko l wierszy i aktualizować w nich l wartości. Ponieważ l jest znacząco mniejsze niż n, złożoność spada do $O(n)$.

\subsubsection{Złożoność pamięciowa}
Zaimplementowana przeze mnie struktura \texttt{BlockMatrix} przechowuje naszą macierz blokową A. Korzysta przy tym ze \texttt{SparseArrays} dostępnych w języku Julia. \texttt{SparseArrays} nie przechowują niezerowych elementów, wobec tego, ze względu na budowę A, mamy tylko elementy zlokalizowane w otoczeniu przekątnej. Ponieważ jest to co najwyżej l elementów przypadających na każdy wiersz/kolumnę, których jest n, to ze względu, że l jest jakąś stałą, złożoność pamięciowa to $O(n)$.

\subsubsection{Pseudokod}
Każde wykonanaie pętli \texttt{for} jest ograniczone do pewnych indeksów, dla których występują niezerowe elementy. Dzięki temu dokonujemy optymalizowania opisanego we wcześniejszym paragrafie i ograniczamy nasze obliczenia tylko do tych elementów, które mają rzeczywisty wpływ na wynik. Dodatkowo korzystamy z własności SparseArrays. 
\begin{itemize}
  \item \texttt{nzval} - wektor wartości wszystkich niezerowych elementów.
  \item \texttt(colptr) - wektor wskaźników kolumn o długości n+1 (dla macierzy o n wierszach i n kolumnach). Dla kolumny $j$ niezerowe wpisy znajdują się na pozycjach $k = colptr[j]:colptr[j+1]-1$,
  \item \texttt{rowval} - wektor indeksów wierszy odpowiadających kolejnym elementom w \texttt{nzval},
\end{itemize}

\newpage

\begin{algorithmic}[1]
\Procedure{GaussElimination}{$A, b$}
  \State $M \gets A.matrix,\; n \gets A.size[1]$
  \State \text{Zbuduj reprezentację wierszową: \texttt{rows[1..n]} jako mapy kolumna->wartość}
  \For{col = 1 \textbf{to} $M.n$}
    \For{każdy niezerowy wpis $(r,\;v)$ w kolumnie \texttt{col}}
      \State \texttt{rows[r][col] = v}
    \EndFor
  \EndFor

  \State \Comment{Forward elimination (bez pivotingu), ograniczona do okna blokowego}
  \For{$k = 1$ \textbf{to} $n-1$}
    \If{brak elementu diagonalnego \texttt{rows[k][k]}} \State \textbf{error}("Zero pivot") \EndIf
    \State $pivot \gets \texttt{rows[k][k]}$
    \For{$i = k+1$ \textbf{to} $\min(n,\;k + A.block\_size + 1)$}
      \State $a_{ik} \gets \texttt{get(rows[i], k, 0)}$
      \If{$a_{ik} = 0$} \textbf{continue} \EndIf
      \State $m \gets a_{ik} / pivot$
      \State \Comment{Zaktualizuj wiersz $i$: dla kolumn $j>k$ wykonaj $a_{ij} \mathrel{-}= m\cdot a_{kj}$}
      \For{każde $(j, a_{kj})$ w \texttt{rows[k]} z $j>k$}
        \State $val \gets \texttt{get(rows[i], j, 0)} - m\cdot a_{kj}$
        \If{$|val| <$ tol}  delete \texttt{rows[i][j]} \Else \texttt{  rows[i][j]=val} \EndIf
      \EndFor
      \State delete \texttt{rows[i][k]} \Comment{eliminowany element poniżej przekątnej}
      \State $b[i] \mathrel{-}= m\cdot b[k]$ \Comment{aktualizacja wektora prawej strony}
    \EndFor
  \EndFor
  \State \Comment{Back substitution: rozwiąż Ux = b}
  \State $x \gets$ wektor zer długości $n$
  \If{brak \texttt{rows[n][n]}}  \textbf{error}("Zero diagonal") \EndIf
  \State $x[n] \gets b[n] / \texttt{rows[n][n]}$
  \For{$i = n-1$ \textbf{downto} $1$}
    \State $s \gets b[i]$
    \For{each $(j,a_{ij})$ w \texttt{rows[i]} z $j>i$}
      \State $s \mathrel{-}= a_{ij}\cdot x[j]$
    \EndFor
    \If{brak \texttt{rows[i][i]}}  \textbf{error}("Zero diagonal") \EndIf
    \State $x[i] \gets s / \texttt{rows[i][i]}$
  \EndFor

  \State \Return $x$
\EndProcedure
\end{algorithmic}

\subsection{Wariant drugi - z częściowym wyborem \\elementu głównego}
Ten wariant ma zabezpieczać nas przed potencjalnym dzieleniem przez $0$ gdy na przekątnej macierzy taka warotść się znajduje. Biorąc pod uwagę, że obliczenia wykonujemy na komputerze, liczby bardzo zbliżone do $0$ również są tymi, które mogą nam zwrócić błąd.

Element główny to nic innego jak wybrana wartość, którą będziemy używać aby wyzerować pozostałe w kolumnie. Wybieramy ją poprzez znaleznienie największej wartości w kolumnie (patrząc na jej moduł). Następnie wyznaczamy czynnik, przez który będziemy mnożyć kolejne wiersze, korzystając już z tej największej wartości. Zapamiętujemy, które wiersze zostały zamienione za pomocą tablicy permutacji. Dzięki temu nie modyfikujemy macierzy A, a odwołując się do konkretnego wiersza zamiast używać jego indeksu wprost, używamy \texttt{p[indeks]}. 

\subsubsection{Złożoność czasowa}
Algorytm z wyborem elementu głównego jest bardzo podobny do zwykłej eliminacji Gaussa. Jedyna różnica polega na tym, że w pierwszej pętli \texttt{for} gdy przechodzimy po kolumnach wybieramy największą wartość w danej kolumnie. Następnie wykonujemy, tak samo, resztę algorytmu na zmienionej kolejności wierszy. Ta jedna dodatkowa pętla nawet w niezoptymalizowanej wersji nie zwiększyłaby złożoności algorytmu. Wobec tego pozostaje, identycznie jak poprzednio, złożność czasowa równa $O(n)$.
\subsubsection{Złożoność pamięciowa}
W tym algorytmie mamy dodatkową tablicę permutacji. Jest ona rozmiaru $n$, który odpowiada liczbie wierszy w macierzy. Poza nią wszystko jest przechowywane tak samo jak poprzednio. Czyli, wszystkie modyfikacje wykonywane są in-place na macierzy A. Jak już wspomniałam wcześniej tablica permutacji ma n elementów, a więc nie zmienia to rzędu pamięci. Wobec tego złożoność pamięciowa to dalej $O(n)$.

\subsubsection{Pseudokod}
Robimy dokładnie to samo co w poprzednim przypadku. Jedynie po pierwszej pętli \texttt{for} dla każdej kolumny wybieramy element o największej co do wartości bezwzględnej wartości i wybieramy go jako element główny. Permutacje wierszy przechowujemy w tablicy \texttt{p}, którą potem wykorzystujemy. Odwołując się do jakiegokolwiek wiersza \texttt{i} używamy po prostu \texttt{p[i].} Poniżej sam schemat częściowego wyboru elementu głównego.

\newpage
\begin{algorithmic}[1]
\State $pivot \gets k$
\State $maxval \gets |\,\texttt{get}(rows[p[k]], k, 0)\,|$
\For{$r = k+1$ \textbf{to} $bound$}
  \State $val \gets |\,\texttt{get}(rows[p[r]], k, 0)\,|$
  \If{$val > maxval$}
    \State $maxval \gets val$
    \State $pivot \gets r$
  \EndIf
\EndFor
\If{$pivot \ne k$}
  \State swap $p[k]$ and $p[pivot]$ \Comment{aktualizacja wektora permutacji}
\EndIf
\State \Return $p$
\end{algorithmic}


\section{Rozkład LU}
Rozkład LU to taki podział, w którym A = LU. Czyli zamieniamy macierz A na dwie macierze trójkątne. L jest macierzą dolnotrójkątną, a U górnotrójkątną. L zawiera mnożniki $l_{ik}$ w miejscu zerowanych elementów. 


\[
L =
\begin{pmatrix}
1        & \cdots  &        &        & 1      \\
m_{21}   & 1       & \cdots &        &        \\
m_{31}   & m_{32}  & 1      & \cdots &        \\
\vdots   & \vdots  & \ddots & \ddots & \vdots \\
m_{n1}   & m_{n2}  & \cdots & m_{n,n-1} & 1
\end{pmatrix}
\]

\[
U =
\begin{pmatrix}
u_{11} & u_{12} & \cdots & u_{1n} \\
0      & u_{22} & \cdots & u_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
0      & 0      & \cdots & u_{nn}
\end{pmatrix}
\]\\

Znając LU sprowadzamy nasz problem do rozwiązania
\[
Ly = b
\]
\[
Ux = y
\]

Podczas obliczeń, aby odszczędzać miejsce, będziemy modyfikować macierz A, tak aby pod przekątną znalazło się L a pozostałe miejsca były zajęte przez U.

\subsection{Wariant pierwszy - bez wyboru elementu głównego}

\subsubsection{Złożoność czasowa}
Po przyjrzeniu się algorytmowi na wyznaczenie LU zauważymy, że jest on bardzo podobny do procesu eliminacji w eliminacji Gaussa. Występują dokładnie te same obliczenia z tą różnicą, że macierz A jest modyfikowana i zapisywane są wewnątrz niej wartości L oraz U. Z tego powodu możemy stwierdzić, że złożoność czasowa tego algorytmu to również $O(n)$.

\subsubsection{Złożoność pamięciowa}
Jeśli chodzi o złożoność pamięciową to LU zapisujemy w A (L jest macierzą dolnotrójkątną a U górnotrójkątną). Obydwie macierze mają tą samą strukturę. Więc złożoność pamięciowa wynosi $O(n)$.


\subsubsection{Uwagi do kodu}
Algorytm jest bardzo podobny do zwykłej eliminacji Gaussa z tą różnicą, że zamiast zerować pierwszy niezerowy element poniżej przekątnej (ten, który znajduje się w liczniku podczas obliczania czynnika $m$), zapisujemy w tym miejscu czynnik $m$ - używany do zerowania wierszy poniżej diagonali.

\subsection{Wariant drugi - z częciowym wyborem \\elementu głównego}
Analogicznie jak w przypadku eliminacji Gaussa z częściowym wyborem, ten wariant zapobiega błędom numerycznym w przypadku bliskim lub równym zera wartościom na przekątnej macierzy A. Lekko modyfikujemy podstawowy algorytm wyznaczania rozkładu LU, zamieniając wiersze miejscami i zapamiętując tablicę permutacji. W tym samym momencie odpowiednio modyfikujemy macierz A tworząc z niej macierz LU.

\subsubsection{Złożoność czasowa}
W tym algorytmie występuje taka sama pętla \texttt{for}, odpowiedzialna za szukanie największego elementu w kolumnie, jak w wypadku eliminacji Gaussa z częściowym wyborem elementu głównego. Następnie algorytm wyznaczania rozkłau LU wygląda niemal identycznie jak faza eliminacji z tą różnicą, że macierz A jest wtedy odpowiednio modyfikowana. Wobec tego złożoność czasowa algorytmu to $O(n)$.

\subsubsection{Złożoność pamięciowa}
Uzasadnienie, że złożoność pamięciowa algorytmu wynosi $O(n)$ nasuwa się samo. Skoro dominującym czynnikiem jest tu macierz A, którą modyfikujemy in-place i w żadnym momencie nie potrzebujemy tworzenia dodatkowej kopii (z wyjątkiem macierzy permutacji, ale zostało już wytłumaczone dlaczego nie jest to problemem) albo nowej struktury to złożoność wynosi $O(n)$.

\section{Eksperymenty}
\begin{figure}[H]
  \centering
  \begin{minipage}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\linewidth]{results/mem_plot.png}
    \caption{Wykres pamięci od razmiaru macierzy}
    \label{fig:ob1}
  \end{minipage}\hfill
  \begin{minipage}[b]{0.48\textwidth}
    \centering
    \includegraphics[width=\linewidth]{results/time_plot.png}
    \caption{Wykres czasu od rozmiaru macierzy}
    \label{fig:ob2}
  \end{minipage}
\end{figure}

\subsection{Wnioski}

Powyżej znajduje się porównanie wszystkich czterech zaimplementowanych algorytmów. Widzimy, że obydwa wykresy: pamięci i czasu są liniowe względem rozmiaru macierzy, czyli zaimplementowane przeze mnie rozwiązanie spełnia warunki zadania. W przypadku wykresu pamięci algorytmy, które generują nam macierz LU a następnie rozwiązują układ używając jej, mają trochę większą złożoność niż zwykły algorytm Gaussa. Jest to zgodne z intuicją, ponieważ generując LU automatycznie przechowujemy więcej elementów w samej macierzy niż oryginalnie. Również w przypadku czasu wykonania są one trochę wolniejsze niż metody eliminacji Gaussa z częściowym wyborem elementu głównego oraz bez. Jeśli natomiast chodzi o rozróżnienie algorytmów pod kątem częściowego wyboru elementu głównego to pamięciowo zarówno algorytm z LU jak i zwykły Gauss zajmują pamięciowo porównywalnie tyle samo miejsca, jednak wersje z wyborem elementu głównego są wolniejsze. Jest to zgodne z tym, że pivotowanie wymaga dodatkowych operacji (wyszukiwanie maksimum, permutacje). Koszt ten jednak jest niewielki, a takie algorytmy są bardziej stabilne.

\end{document}